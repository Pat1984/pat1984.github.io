import{_ as e,c as t,o as i,b as n}from"./app-DNGkhXUj.js";const o={},a=n('<h2 id="models" tabindex="-1"><a class="header-anchor" href="#models"><span>Models</span></a></h2><p>When using Stable Diffusion, it&#39;s important to understand the types and functions of the SD (Stable Diffusion) models. Below is a summary of the categories and functions of various models:</p><ol><li><p><strong>Base Model</strong></p><ul><li>The base model is responsible for learning a vast array of artistic paintings and design images, enabling the generation of more accurate, textured, and vivid graphics. It is commonly used for digital and anime-style image generation. The size of the base model typically ranges from 2GB to 10GB, with the latest Stable Diffusion 3&#39;s base model being around 10GB.</li></ul></li><li><p><strong>Embedding Model</strong></p><ul><li>The embedding model is a deep learning-based image processing model, part of a generative adversarial network (GAN), consisting of two components: the generator and the discriminator. By iterating and training the embedding model, the generator and discriminator can be continuously optimized for applications such as movie visual effects, game development, and virtual reality. In Stable Diffusion, the embedding model is often metaphorically described by those studying Stable Diffusion as a small yet exquisite bookmark within a large model, aiding other models in more precisely depicting the output of images. The size of the embedding model is around 50KB, with the file extensionÂ <code>pt</code>.</li></ul></li><li><p><strong>Hypernetwork Model</strong></p><ul><li>The hypernetwork model is a model that generates neural network weights, typically used in Stable Diffusion to train painting styles and assist in adjusting the overall working method of the model.</li></ul></li><li><p><strong>LoRA Model</strong></p><ul><li>The LoRA (Low-Rank Adaptation) model is a fine-tuning model for the base model. It allows for the training of a particular painting style or character without modifying the base model itself, using a small amount of data to meet customized requirements. The model size is generally under 1GB, typically ranging from 20MB to 200MB.</li></ul></li></ol><p>Understanding these models and their functionalities can help users of Stable Diffusion to select the appropriate model for their specific needs and achieve better results in image generation and processing tasks.</p>',4),s=[a];function l(r,d){return i(),t("div",null,s)}const g=e(o,[["render",l],["__file","20240717Types of Models.html.vue"]]),p=JSON.parse(`{"path":"/posts/stable%20diffusiion%20overview%20and%20design%20theory/20240717Types%20of%20Models.html","title":"","lang":"en-US","frontmatter":{"description":"Models When using Stable Diffusion, it's important to understand the types and functions of the SD (Stable Diffusion) models. Below is a summary of the categories and functions ...","head":[["meta",{"property":"og:url","content":"https://pat1984.github.io/posts/stable%20diffusiion%20overview%20and%20design%20theory/20240717Types%20of%20Models.html"}],["meta",{"property":"og:site_name","content":"Patience Hong"}],["meta",{"property":"og:description","content":"Models When using Stable Diffusion, it's important to understand the types and functions of the SD (Stable Diffusion) models. Below is a summary of the categories and functions ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"article:author","content":"Patience Hong"}],["meta",{"property":"og:updated_time","content":"2024-08-06T09:08:43.525Z"}],["meta",{"property":"og:modified_time","content":"2024-08-06T09:08:43.525Z"}],["meta",{"name":"twitter:description","content":"Models When using Stable Diffusion, it's important to understand the types and functions of the SD (Stable Diffusion) models. Below is a summary of the categories and functions ..."}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:site","content":"Patience in Sirus"}],["meta",{"name":"twitter:creator","content":"Patience in Sirus"}],["meta",{"name":"share_config","content":"twitter,weibo,facebook,email"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Patience Hong\\"}]}"]]},"headers":[{"level":2,"title":"Models","slug":"models","link":"#models","children":[]}],"git":{},"filePathRelative":"posts/stable diffusiion overview and design theory/20240717Types of Models.md","autoDesc":true,"excerpt":"<h2>Models</h2>\\n<p>When using Stable Diffusion, it's important to understand the types and functions of the SD (Stable Diffusion) models. Below is a summary of the categories and functions of various models:</p>\\n<ol>\\n<li>\\n<p><strong>Base Model</strong></p>\\n<ul>\\n<li>The base model is responsible for learning a vast array of artistic paintings and design images, enabling the generation of more accurate, textured, and vivid graphics. It is commonly used for digital and anime-style image generation. The size of the base model typically ranges from 2GB to 10GB, with the latest Stable Diffusion 3's base model being around 10GB.</li>\\n</ul>\\n</li>\\n<li>\\n<p><strong>Embedding Model</strong></p>\\n<ul>\\n<li>The embedding model is a deep learning-based image processing model, part of a generative adversarial network (GAN), consisting of two components: the generator and the discriminator. By iterating and training the embedding model, the generator and discriminator can be continuously optimized for applications such as movie visual effects, game development, and virtual reality. In Stable Diffusion, the embedding model is often metaphorically described by those studying Stable Diffusion as a small yet exquisite bookmark within a large model, aiding other models in more precisely depicting the output of images. The size of the embedding model is around 50KB, with the file extension&nbsp;<code>pt</code>.</li>\\n</ul>\\n</li>\\n<li>\\n<p><strong>Hypernetwork Model</strong></p>\\n<ul>\\n<li>The hypernetwork model is a model that generates neural network weights, typically used in Stable Diffusion to train painting styles and assist in adjusting the overall working method of the model.</li>\\n</ul>\\n</li>\\n<li>\\n<p><strong>LoRA Model</strong></p>\\n<ul>\\n<li>The LoRA (Low-Rank Adaptation) model is a fine-tuning model for the base model. It allows for the training of a particular painting style or character without modifying the base model itself, using a small amount of data to meet customized requirements. The model size is generally under 1GB, typically ranging from 20MB to 200MB.</li>\\n</ul>\\n</li>\\n</ol>"}`);export{g as comp,p as data};
